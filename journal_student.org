# -*- coding: utf-8 -*-
#+STARTUP:
#+TITLE:       Experimentations on sorting algorithms
#+AUTHOR:      RÃ©mi GATTAZ
#+LANGUAGE:    en
#+TAGS: IMPORTANT(i) TEST(t) DEPRECATED(d) noexport(n)


* Preparation

** Compilation
As I work on OSX, and the project is prepared for students working using linux, the compilation chain that was given didn't work for me. To compile the project without errors, I had to remove the options "-pthread", "-lrt" and "-finline-functions" from the Makefile.


** Scripts
To be able to use the script more easily, I made them executable.

: chmod a+x scripts/*


* Experiments

** Experiment 1 :

For this first experiment, we decided to redo the given tests but make a bit more iterations. The idea is to see if the first approximation that is given by the teacher seems to be coherent or not.

So I modified the run-benchmark.sh script to make 30 tests for every array size.

Also, to reflect on the usage of the machine a bit better on the results, we inverted the two loops of the scripts. Instead of making for every size n tests, we make n tests of every size. (This last sentence is probably not clear :-))

I obtained the following script :
#+begin_src sh foo :results output :exports both :tangle scripts/run_benchmarking2.sh
    #!/bin/sh

    OUTPUT_DIRECTORY=data/`hostname`_`date +%F`
    mkdir -p $OUTPUT_DIRECTORY
    OUTPUT_FILE=$OUTPUT_DIRECTORY/measurements_`date +%R`.txt

    touch $OUTPUT_FILE
    for rep in `seq 1 30`; do
        echo "Seq = $rep"
        for i in 100 1000 10000 100000 1000000; do
            echo "Size: $i" >> $OUTPUT_FILE;
            ./src/parallelQuicksort $i >> $OUTPUT_FILE;
        done ;
    donesds
#+end_src

Using this script, I had the following [[file:data/remiBookPro13_2016-01-21/measurements_12:31.txt][results]].

This file follows the exact same syntax as the one created by the previous experiment. I was thus able to use the script csv_quicksort_extractor.pl to create a csv.

#+begin_src sh :results output :exports both
./scripts/csv_quicksort_extractor.pl < data/remiBookPro13_2016-01-21/measurements_12:31.txt > data/remiBookPro13_2016-01-21/measurements_12:31.txt:31.csv
#+end_src

Using the CSV, I was then able to draw the results :
#+begin_src R :results output graphics :file data/remiBookPro13_2016-01-21/measurements_12:31.png :exports both :width 600 :height 400 :session
    df <- read.csv("data/remiBookPro13_2016-01-21/measurements_12:31.csv",header=T)
    plot(df$Size,df$Time,col=c("red","blue","green")[df$Type])
#+end_src

#+begin_src R results output :session :exports both
    library(dplyr)
    df_mine <- df %>% group_by(Size, Type) %>%
                      select(Time) %>%
                      summarise( num = n(),
			         Time_mean = mean(Time),
				 Time_sd = sd(Time),
				 Time_se = 2*Time_sd/sqrt(num)
			       )
    df_mine
#+end_src

#+begin_src R :results output graphics :file data/remiBookPro13_2016-01-21/measurements_12:31.png :exports both :width 600 :height 400 :session
    library(ggplot)

    ggplot(data = df_mine,
           aes(x=Size , y=Time_mean, ymin=Time_mean-Time_se, ymax=Time_mean+Time_se, color=Type) ) +
	   geom_crossbar() +
	   geom_point() +
	   geom_line();

#+end_src



#+RESULTS:
[[file:data/remiBookPro13_2016-01-21/measurements_12:31.png]]

The results for the sequential and the Built-in version seems coherent with the previous estimation. The Parallel one however doesn't. The deviance between the values found seems to be big.


** Experiment 2 : Test Routines


During this experiment, we will not generate a new tests bu try to make the previous one more fair. Our goal is 
to create a test protocol in which tests are sequentially made in a random order. 

On top of this, we will not store the test routine. That way, if the experiment is run several times, there are no guarantees
that the tests will be executed in the same order.

#+begin_src R foo :results output :exports both :tangle scripts/generator_experiment2.R
    #!/usr/bin/env Rscript

    nbTests <- 5
    sizes <- c(100, 1000, 10000, 100000, 1000000)
    options(scipen=999) #disable the scientific notation

    # First, create a vector containing all array sizes
    vectTests = c();
    i <- 1
    for(size in sizes){
        for(rep in 1:nbTests){
            vectTests[i] <- size
            i <- i + 1
        }
    }

    # Then, shuffle this array by making a sample
    vectTests <- sample(vectTests)

    # Finally, write each element of this vector on a line in stdout
    cat(vectTests, sep='\n')
#+end_src

In this version, the test routine is simply a list of sizes. Each line contains a number that represents the size 
of the array that must be sorted.

Beeing runnable, this R script can thus be run using a bash file.

#+begin_src sh foo :results output :exports both :tangle scripts/run_benchmarking3.sh
    #!/bin/sh

    OUTPUT_DIRECTORY=data/`hostname`_`date +%F`
    mkdir -p $OUTPUT_DIRECTORY
    OUTPUT_FILE=$OUTPUT_DIRECTORY/measurements_`date +%R`.txt

    rm -f $OUTPUT_FILE
    touch $OUTPUT_FILE
    scripts/generator_exp2.R | xargs -n1 -I {size} \
        sh -c 'echo "Size: "{size}; ./src/parallelQuicksort {size}' >> $OUTPUT_FILE
#+end_src

Using this scripts, I was able to get the following [[file:data/remiBookPro13_2016-02-04/measurements_19:24.txt][results]]

As the goal of this experiment was not to have new results but to have a good way to use R to generate tests routines,
 I did not analyse these results.



** Ideas for next experiments :
- Try to change the number of available threads used in the paralleled version of the quicksort.

1
