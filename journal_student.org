# -*- coding: utf-8 -*-
#+STARTUP:
#+TITLE:       Experimentations on sorting algorithms
#+AUTHOR:      RÃ©mi GATTAZ
#+LANGUAGE:    en
#+TAGS: IMPORTANT(i) TEST(t) DEPRECATED(d) noexport(n)


* Preparation

** Compilation
As I work on OSX, and the project is prepared for students working using linux, the compilation
chain that was given didn't work for me. To compile the project without errors, I had to remove the
options "-pthread", "-lrt" and "-finline-functions" from the Makefile.


** Scripts
To be able to use the script more easily, I made them executable.

: chmod a+x scripts/*


* Experiments

** Experiment 1 :

For this first experiment, we decided to redo the given tests but make a bit more iterations. The
idea is to see if the first approximation that is given by the teacher seems to be coherent or not.

So I modified the run-benchmark.sh script to make 30 tests for every array size.

Also, to reflect on the usage of the machine a bit better on the results, we inverted the two loops
of the scripts. Instead of making for every size n tests, we make n tests of every size.

I obtained the following script :
#+begin_src sh foo :results output :exports both :tangle scripts/run_benchmarking1.sh
    #!/bin/sh

    OUTPUT_DIRECTORY=data/`hostname`_`date +%F`
    mkdir -p $OUTPUT_DIRECTORY
    OUTPUT_FILE=$OUTPUT_DIRECTORY/measurements_`date +%R`.txt

    touch $OUTPUT_FILE
    for rep in `seq 1 30`; do
        echo "Seq = $rep"
        for i in 100 1000 10000 100000 1000000; do
            echo "Size: $i" >> $OUTPUT_FILE;
            ./src/parallelQuicksort $i >> $OUTPUT_FILE;
        done ;
    donesds
#+end_src

Using this script, I had the following
[[file:data/remiBookPro13_2016-01-21/measurements_12:31.txt][results]].

This file follows the exact same syntax as the one created by the previous experiment. I was thus
able to use the script csv_quicksort_extractor.pl to create a csv.

#+begin_src sh :results output :exports both
    ./scripts/csv_quicksort_extractor.pl < data/remiBookPro13_2016-01-21/measurements_12:31.txt > data/remiBookPro13_2016-01-21/measurements_12:31.txt:31.csv
#+end_src

Using the CSV, I was then able to draw the results :
#+begin_src R :results output graphics :file data/remiBookPro13_2016-01-21/measurements_12:31.png :exports both :width 600 :height 400 :session
    df <- read.csv("data/remiBookPro13_2016-01-21/measurements_12:31.csv",header=T)
    plot(df$Size,df$Time,col=c("red","blue","green")[df$Type])
#+end_src

#+RESULTS:
[[file:data/remiBookPro13_2016-01-21/measurements_12:31.png]]

#+begin_src R results output :session :exports both
    library(dplyr)
    df_mine <- df %>% group_by(Size, Type) %>%
                      select(Time) %>%
                      summarise( num = n(),
                            Time_mean = mean(Time),
                            Time_sd = sd(Time),
                            Time_se = 2*Time_sd/sqrt(num)
                      )
    df_mine
#+end_src

#+begin_src R :results output graphics :file data/remiBookPro13_2016-01-21/measurements_ggplot_12:31.png :exports both :width 600 :height 400 :session
    library(ggplot2)

    ggplot(data = df_mine,
        aes(x=Size , y=Time_mean, ymin=Time_mean-Time_se, ymax=Time_mean+Time_se, color=Type) ) +
        geom_crossbar() +
        geom_point() +
        geom_line();

#+end_src



#+RESULTS:
[[file:data/remiBookPro13_2016-01-21/measurements_ggplot_12:31.png]]

The results for the sequential and the Built-in version seems coherent with the previous estimation.
The Parallel one however doesn't. The deviance between the values found seems to be big.


** Experiment 2 : Test Routines


During this experiment, we will not generate a new tests bu try to make the previous one more fair.
Our goal is to create a test protocol in which tests are sequentially made in a random order.

On top of this, we will not store the test routine. That way, if the experiment is run several
times, there are no guarantees that the tests will be executed in the same order.

#+begin_src R foo :results output :exports both :tangle scripts/generator_experiment2.R
    #!/usr/bin/env Rscript

    nbTests <- 5
    sizes <- c(100, 1000, 10000, 100000, 1000000)
    options(scipen=999) #disable the scientific notation

    # First, create a vector containing all array sizes
    vectTests = c();
    i <- 1
    for(size in sizes){
        for(rep in 1:nbTests){
            vectTests[i] <- size
            i <- i + 1
        }
    }

    # Then, shuffle this array by making a sample
    vectTests <- sample(vectTests)

    # Finally, write each element of this vector on a line in stdout
    cat(vectTests, sep='\n')
#+end_src

In this version, the test routine is simply a list of sizes. Each line contains a number that
represents the size of the array that must be sorted.

Beeing runnable, this R script can thus be run using a bash file.

#+begin_src sh foo :results output :exports both :tangle scripts/run_benchmarking2.sh
    #!/bin/sh

    OUTPUT_DIRECTORY=data/`hostname`_`date +%F`
    mkdir -p $OUTPUT_DIRECTORY
    OUTPUT_FILE=$OUTPUT_DIRECTORY/measurements_`date +%R`.txt

    rm -f $OUTPUT_FILE
    touch $OUTPUT_FILE
    scripts/generator_exp2.R | xargs -n1 -I {size} \
        sh -c 'echo "Size: "{size}; ./src/parallelQuicksort {size}' >> $OUTPUT_FILE
#+end_src

Using this scripts, I was able to get the following
[[file:data/remiBookPro13_2016-02-04/measurements_19:24.txt][results]]

As the goal of this experiment was not to have new results but to have a good way to use R to
generate tests routines, I did not analyse these results.


** Experiment 3 : Thread levels

In the parallel quicksort, the number of available theads is set to 10. During this experiment, we
will try to modify this value to see how it impacts the results. For this experiment we will have to
use exactly the same data for every thread level we try. it implies we will need to manually set the
seed in the C programm generating the random arrays.

Before this, we need to modify the source code of our sorting program to take handle more
parameters : a seed and a thread level.

#+begin_src C
int main(int argc, char *argv[])
{
    // [...]
    int NUM = DNUM;
    int seed = time(NULL);
    int THREAD_LEVEL = DTHREAD_LEVEL;
    if (argc == 2)              //user specified list size.
    {
        NUM = atoi(argv[1]);
    }else if (argc == 4)        //user specified list size, seed and thread level.
    {
        NUM = atoi(argv[1]);
        seed = atoi(argv[2]);
        THREAD_LEVEL = atoi(argv[3]);
    }

    srand(seed);                //initialisation of seed
#+end_src

During the previous experiments, the number of threads used during the parrallel quicksort was
fixed. In this experiment, we will create a routine in which this number will vary.

To do, we created the following R script to generate the routine :

#+begin_src R foo :results output :exports both :tangle scripts/generator_experiment3.R
    #!/usr/bin/env Rscript

    nbTests <- 15
    sizes <- c(100, 1000, 10000, 100000, 1000000)
    threadsLevels <- c(4, 6, 8, 10, 12, 14, 16)
    seeds <- c()
    options(scipen=999) #disable the scientific notation

    # First, generate seeds (one for every size for every repetition)
    testsSeeds <- round(runif(nbTests * length(sizes), 1, 100000000))

    # Then, create a vector containing the array sizes
    testsSizes = c();
    i <- 1
    for(size in sizes){
        for(rep in 1:nbTests){
            testsSizes[i] <- size
            i <- i + 1
        }
    }

    # Now, we will replicate the testsSizes and testsSeeds to run them for every threadLevel
    # We also create the testsLevels vector
    testsSizes <- rep(testsSizes, length(threadsLevels))
    testsSeeds <- rep(testsSeeds, length(threadsLevels))
    testsLevels <- rep(threadsLevels, each=nbTests * length(sizes))

    # Finally, creation of the dataframe
    testsDF <- data.frame(testsSizes, testsSeeds, testsLevels)
    # and shuffle
    testsDF <- testsDF[sample(nrow(testsDF)),]


    # print the dataframe without the row and column names
    # On each line, there is the size, the seed to use and the thread level
    write.table(testsDF, row.names = FALSE, col.names=FALSE)
#+end_src

The script we used during the second experiment was simply creating a vector and shuffling it. This
time however, we needed to create a dataframe since we are now handling several information per
test.

The data contained in the routine this script creates is a bit different than the one we had in the
previous experiment. Since we have several data per line, we will have  as there are now 3
informations per line. We will have to adapt a bit the script used in the previous experiment.

#+begin_src sh foo :results output :exports both :tangle scripts/run_benchmarking3.sh
    #!/bin/sh

    OUTPUT_DIRECTORY=data/`hostname`_`date +%F`
    mkdir -p $OUTPUT_DIRECTORY
    OUTPUT_FILE=$OUTPUT_DIRECTORY/measurements_`date +%R`.txt

    rm -f $OUTPUT_FILE
    touch $OUTPUT_FILE
    scripts/generator_exp3.R | xargs -n1 -I {args} \
        sh -c 'echo "Args: "{args}; ./src/parallelQuicksort {args}' >> $OUTPUT_FILE
#+end_src

Running this created the following [[file:data/sama_2014-02-04/measurements_23:17.txt][output]]

Now, to use the data, we need to tranform the text file we just created into a csv. The two perl
scripts used before cannot be used anymore either. We thus created the following script :

#+begin_src perl :results output raw :exports both :tangle scripts/csv_quicksort_extractor3.pl
    #!/usr/bin/perl

    use strict;

    my($line);
    my($size,$seed,$level);
    my($seq,$par,$libc);
    print "Size, Seed, Level, Seq, Par, Libc\n" ;
    while($line=<>) {
        chomp $line;

        if($line =~/Args: (\d+) (\d+) (\d+)$/) {
            $size = $1;
            $seed = $2;
            $level = $3;
            next;
        }
        if($line =~/^Sequential quicksort.*: ([\d\.]*) sec.$/) {
            $seq=$1; next;
        }
        if($line =~/^Parallel quicksort.*: ([\d\.]*) sec.$/) {
            $par=$1; next;
        }
        if($line =~/^Built-in quicksort.*: ([\d\.]*) sec.$/) {
            $libc=$1;
            print "$size, $seed, $level, $seq, $par, $libc\n";
            next;
        }
    }
#+end_src

I can use this extractor just like the others.

#+begin_src sh :results output :exports both
    perl scripts/csv_quicksort_extractor3.pl < data/remiBookPro13_2016-02-04/measurements_23:17.txt > data/remiBookPro13_2016-02-04/measurements_23:17.csv
#+end_src

Now, we can load the data into R.

#+begin_src R :results output :session :exports both
    df <- read.csv("data/remiBookPro13_2016-02-04/measurements_23:17.csv",header=T)
    library(dplyr)

    df_extra <- df %>% group_by (Level, Size) %>%
                   select(Par) %>%
                   summarise (
                       num = n(),
                       Par_mean = mean(Par),
                       Par_sd = sd(Par),
                       Par_se = 2*Par_sd/sqrt(num)
                   )
    df_extra
#+end_src

We are trying to look at the impact of the value of Thread_level in the parallel version of the quicksort. Therefore, only the values of the parallel tests are interesting us now.

#+begin_src R :results output graphics :file data/remiBookPro13_2016-02-04/measurements_Seq_23:17.png :exports both :width 600 :height 400 :session
    library(ggplot2)
    ggplot(data = df_extra,
        aes(x=Size , y=Par_mean, ymin=Par_mean-Par_se, ymax=Par_mean+Par_se, color=factor(Level)) ) +
        geom_crossbar() +
        geom_point() +
        geom_line();
#+end_src

#+RESULTS:
[[file:data/remiBookPro13_2016-02-04/measurements_Seq_23:17.png]]


The data in that graph seems to indicate that when the array is small, using a low number of will produce better results. This is most likely due to the fact that creating threads is very expensive.

On the other hand, as anyone would assume, it seems to be better to sort big arrays with more threads. But there seems to be a limit to this phenomenon as sorting 1 000 000 integers is done quicker using 8 threads than when using 10. It is most likely once again due to the cost of creating threads. If the arrays were 100 times that size, using 10 threads would be better than 8.


** Experiment 4 : Linear regressions

In this experiment, we will try to make a linear regression. The goal is to approximate using this regression how the system will behave with really big arrays. At first, we will do this experiment
using the default thread_level.

To be able to make a good approximation, we will have to generate tests with arrays of random sizes. The sizes are generated randomly following
a uniform distribution between 1 and 10 000 000.

The experiment generator will thus become this :
#+begin_src R foo :results output :exports both :tangle scripts/generator_experiment4.R
    #!/usr/bin/env Rscript

    nbTests <- 1000
    sizeMin <- 1
    sizeMax <- 1000000
    options(scipen=999) #disable the scientific notation

    # Create a vector containing all array sizes
    testSizes <- round(runif(nbTests, min=sizeMin, max=sizeMax))

    #  Write each element of this vector on a line in stdout
    cat(vectTests, sep='\n')
#+end_src

Now, let's run the experiment using the benchmarking4.sh script.

#+begin_src sh foo :results output :exports both :tangle scripts/run_benchmarking4.sh
    #!/bin/sh

    OUTPUT_DIRECTORY=data/`hostname`_`date +%F`
    mkdir -p $OUTPUT_DIRECTORY
    OUTPUT_FILE=$OUTPUT_DIRECTORY/measurements_`date +%R`.txt

    rm -f $OUTPUT_FILE
    touch $OUTPUT_FILE
    scripts/generator_exp4.R | xargs -n1 -I {size} \
        sh -c 'echo "Size: "{size}; ./src/parallelQuicksort {size}' >> $OUTPUT_FILE
#+end_src

Using this script, I got the following [[file:data/remiBookPro13_2016-11-04/measurements_16:02.txt][results]] that I can extract with the script extractor2.pl
#+begin_src sh :results output :exports both
    perl scripts/csv_quicksort_extractor2.pl < data/remiBookPro13_2016-02-11/measurements_16:02.txt > data/remiBookPro13_2016-02-11/measurements_16:02.csv
#+end_src


#+begin_src R :results output :session :exports both
    df <- read.csv("data/remiBookPro13_2016-02-11/measurements_16:02.csv",header=T)
#+end_src

#+RESULTS:

First, let's make the regression for the Sequential quicksort.
#+begin_src R foo :results output :exports both :session
    reg <- lm(data=df, Seq~Size);

    summary(reg)
#+end_src

#+RESULTS:
#+begin_example

Call:
lm(formula = Seq ~ Size, data = df)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.01379 -0.00708 -0.00390 -0.00009  0.65244 

Coefficients:
              Estimate Std. Error t value Pr(>|t|)    
(Intercept) -5.977e-03  2.183e-03  -2.738  0.00629 ** 
Size         2.231e-07  3.771e-09  59.169  < 2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.03546 on 998 degrees of freedom
Multiple R-squared:  0.7782,	Adjusted R-squared:  0.7779 
F-statistic:  3501 on 1 and 998 DF,  p-value: < 2.2e-16
#+end_example


In this summary, we can seee that the value of R squared is only 0.77. The estimation isn't very good.

#+begin_src R :results output graphics :file data/remiBookPro13_2016-02-11/measurements_linearSeq_16:02.png :exports both :width 600 :height 400 :session
    library(ggplot2)

    ggplot(data=df, aes(x=Size, y=Seq)) + 
        geom_point() + 
        theme_bw() + 
        geom_smooth(method="lm")
#+end_src

#+RESULTS:
[[file:data/remiBookPro13_2016-02-11/measurements_linearSeq_16:02.png]]

We can see on this graph that some tests are standing abover the others. I was using my computer at the same
time I was running those tests. It is therefore very likely that I created these errors.


Here is now the liner regression of the parallel quicksort :

#+begin_src R foo :results output :exports both :session
    reg <- lm(data=df, Par~Size);

    summary(reg)
#+end_src

#+RESULTS:
#+begin_example

Call:
lm(formula = Par ~ Size, data = df)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.04638 -0.00912 -0.00281  0.00457  0.66554 

Coefficients:
             Estimate Std. Error t value Pr(>|t|)    
(Intercept) 5.903e-02  2.176e-03  27.125  < 2e-16 ***
Size        2.792e-08  3.759e-09   7.427 2.37e-13 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.03535 on 998 degrees of freedom
Multiple R-squared:  0.05238,	Adjusted R-squared:  0.05143 
F-statistic: 55.16 on 1 and 998 DF,  p-value: 2.375e-13
#+end_example

#+begin_src R :results output graphics :file data/remiBookPro13_2016-02-11/measurements_linearPar_16:02.png :exports both :width 600 :height 400 :session
    library(ggplot2)

    ggplot(data=df, aes(x=Size, y=Par)) + 
        geom_point() + 
        theme_bw() + 
        geom_smooth(method="lm")
#+end_src

#+RESULTS:
[[file:data/remiBookPro13_2016-02-11/measurements_linearPar_16:02.png]]



And the linear regression of the libc version :
#+begin_src R foo :results output :exports both :session
    reg <- lm(data=df, Libc~Size);

    summary(reg)
#+end_src

#+RESULTS:
#+begin_example

Call:
lm(formula = Libc ~ Size, data = df)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.02428 -0.01227 -0.00680 -0.00025  0.75446 

Coefficients:
              Estimate Std. Error t value Pr(>|t|)    
(Intercept) -7.218e-03  3.461e-03  -2.085   0.0373 *  
Size         2.432e-07  5.979e-09  40.682   <2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.05622 on 998 degrees of freedom
Multiple R-squared:  0.6238,	Adjusted R-squared:  0.6235 
F-statistic:  1655 on 1 and 998 DF,  p-value: < 2.2e-16
#+end_example

#+begin_src R :results output graphics :file data/remiBookPro13_2016-02-11/measurements_linearLibc_16:02.png :exports both :width 600 :height 400 :session
    library(ggplot2)

    ggplot(data=df, aes(x=Size, y=Libc)) + 
        geom_point() + 
        theme_bw() + 
        geom_smooth(method="lm")
#+end_src

#+RESULTS:
[[file:data/remiBookPro13_2016-02-11/measurements_linearLibc_16:02.png]]

